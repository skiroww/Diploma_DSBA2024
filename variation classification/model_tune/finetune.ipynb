{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/24/2024 08:30:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "c:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1699: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "04/24/2024 08:30:08 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='default', output_dir='comment_model', model_type='gpt2', eval_data_file='valid.txt', line_by_line=False, should_continue=False, model_name_or_path='sberbank-ai/rugpt3small_based_on_gpt2', mlm=False, mlm_probability=0.15, config_name=None, tokenizer_name=None, cache_dir=None, block_size=2048, do_train=True, do_eval=True, evaluate_during_training=False, per_gpu_train_batch_size=1, per_gpu_eval_batch_size=4, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5.0, max_steps=-1, warmup_steps=0, logging_steps=500, save_steps=500, save_total_limit=None, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=True, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'))\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Documents\\github\\He_who_laughs_last\\variation classification\\model_tune\\pretrain_transformers.py\", line 784, in <module>\n",
      "    main()\n",
      "  File \"c:\\Users\\User\\Documents\\github\\He_who_laughs_last\\variation classification\\model_tune\\pretrain_transformers.py\", line 728, in main\n",
      "    train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False)\n",
      "  File \"c:\\Users\\User\\Documents\\github\\He_who_laughs_last\\variation classification\\model_tune\\pretrain_transformers.py\", line 118, in load_and_cache_examples\n",
      "    return TextDataset(tokenizer, args, file_path=file_path, block_size=args.block_size)\n",
      "  File \"c:\\Users\\User\\Documents\\github\\He_who_laughs_last\\variation classification\\model_tune\\pretrain_transformers.py\", line 54, in __init__\n",
      "    assert os.path.isfile(file_path)\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "!python pretrain_transformers.py \\\n",
    "    --output_dir=comment_model \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=sberbank-ai/rugpt3small_based_on_gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=default \\\n",
    "    --do_eval \\\n",
    "    --fp16 \\\n",
    "    --eval_data_file=default \\\n",
    "    --per_gpu_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --block_size 2048 \\\n",
    "    --overwrite_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
